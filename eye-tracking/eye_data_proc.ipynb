{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP1: processing raw eye data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = pd.read_csv(\"../resource/table.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProc():\n",
    "    with open(\"../resource/all.txt\") as f:\n",
    "        contents = f.readlines()\n",
    "        f.close()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    result = []\n",
    "    stm=LancasterStemmer()\n",
    "    for line in contents:\n",
    "        newLine = []\n",
    "        line = re.sub(r\"\\d+\\.?\\d*\",'numchain',line)\n",
    "        line = regex.sub('',line)\n",
    "        line = re.sub(\"ur\",'your',line)\n",
    "        line = line.strip().split()\n",
    "        for item in line:\n",
    "            newLine.append(stm.stem(item))\n",
    "        result.append(newLine)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchEyeData(lemTxt,eye):\n",
    "    seqDict = {'Time to First Fixation_': '0', 'Fixations Before_':'1','First Fixation Duration_':'2','Fixation Duration_':'3','Total Fixation Duration_':'4','Fixation Count_':'5','Fixation Count (Include Zeros)_':'6','Visit Duration_':'7','Total Visit Duration_':'8','Total Visit Duration (Include Zeros)_':'9','Visit Count_':'10','Visit Count (Include Zeros)_':'11'}\n",
    "    wordsSet = set([item for sublist in lemTxt for item in sublist])\n",
    "    result = []\n",
    "    for i in range(3,eye.shape[0]):\n",
    "        arr = np.zeros((50,len(wordsSet)*12))\n",
    "        df = pd.DataFrame(arr,columns=[word+str(i) for word in wordsSet for i in range(12)])\n",
    "        for j in range(1,len(eye.columns)):\n",
    "            col = eye.columns[j]\n",
    "            if not col.endswith('Mean'):\n",
    "                continue\n",
    "            info = col.split('_')\n",
    "            rect = info[2]\n",
    "            if rect == 'Rectangle':\n",
    "                continue\n",
    "            textNum = int(info[1].split()[0])-1\n",
    "            rectNum = int(rect.split()[1])-1\n",
    "            try:\n",
    "                coWord = lemTxt[textNum][rectNum]\n",
    "            except:\n",
    "#                 print(\"error\"+str(textNum))\n",
    "                continue\n",
    "            for key in seqDict.keys():\n",
    "                if col.startswith(key):\n",
    "                    colName = coWord+seqDict[key]\n",
    "                    df.iloc[textNum][colName] = eye.iloc[5,j]\n",
    "                    break\n",
    "        result.append(df)\n",
    "#         break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lemTxt = textProc()\n",
    "eyeMatched = matchEyeData(lemTxt,eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resource/eyeMatched.pkl', 'wb') as f:\n",
    "    pickle.dump(eyeMatched, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP2: Prepare eye-tracking data for ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resource/eyeMatched.pkl', 'rb') as f:\n",
    "    eyeMatched = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = pd.concat(eyeMatched)\n",
    "eye_label = pd.read_pickle('../resource/raw_data')['label'].to_numpy().astype('int').tolist()*len(eyeMatched)\n",
    "\n",
    "data = finalData.to_numpy()\n",
    "label = np.array(eye_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 5784)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clfs = [LogisticRegression(), LinearSVC(),KNeighborsClassifier()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "X = data\n",
    "y = label\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    for  train_index,test_index in skf.split(data,label):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print (accuracy_score(y_test,y_pred))\n",
    "        print (confusion_matrix(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "1.0\n",
      "[[92  0]\n",
      " [ 0 92]]\n",
      "1.0\n",
      "[[92  0]\n",
      " [ 0 91]]\n",
      "1.0\n",
      "[[91  0]\n",
      " [ 0 92]]\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[92  0]\n",
      " [ 0 92]]\n",
      "1.0\n",
      "[[92  0]\n",
      " [ 0 91]]\n",
      "1.0\n",
      "[[91  0]\n",
      " [ 0 92]]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "1.0\n",
      "[[92  0]\n",
      " [ 0 92]]\n",
      "1.0\n",
      "[[92  0]\n",
      " [ 0 91]]\n",
      "1.0\n",
      "[[91  0]\n",
      " [ 0 92]]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "X = data\n",
    "y = label\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    for  train_index,test_index in skf.split(data,label):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print (accuracy_score(y_test,y_pred))\n",
    "        print (confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
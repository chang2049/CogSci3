{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP1: processing raw eye data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = pd.read_csv(\"../resource/table.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProc():\n",
    "    with open(\"../resource/all.txt\") as f:\n",
    "        contents = f.readlines()\n",
    "        f.close()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    result = []\n",
    "    stm=LancasterStemmer()\n",
    "    for line in contents:\n",
    "        newLine = []\n",
    "        line = re.sub(r\"\\d+\\.?\\d*\",'numchain',line)\n",
    "        line = regex.sub('',line)\n",
    "        line = re.sub(\"ur\",'your',line)\n",
    "        line = line.strip().split()\n",
    "        for item in line:\n",
    "            newLine.append(stm.stem(item))\n",
    "        result.append(newLine)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchEyeData(lemTxt,eye):\n",
    "    seqDict = {'Time to First Fixation_': '0', 'Fixations Before_':'1','First Fixation Duration_':'2','Fixation Duration_':'3','Total Fixation Duration_':'4','Fixation Count_':'5','Fixation Count (Include Zeros)_':'6','Visit Duration_':'7','Total Visit Duration_':'8','Total Visit Duration (Include Zeros)_':'9','Visit Count_':'10','Visit Count (Include Zeros)_':'11'}\n",
    "    wordsSet = set([item for sublist in lemTxt for item in sublist])\n",
    "    result = []\n",
    "    for i in range(3,eye.shape[0]):\n",
    "        arr = np.zeros((50,len(wordsSet)*12))\n",
    "        df = pd.DataFrame(arr,columns=[word+str(i) for word in wordsSet for i in range(12)])\n",
    "        for j in range(1,len(eye.columns)):\n",
    "            col = eye.columns[j]\n",
    "            if not col.endswith('Mean'):\n",
    "                continue\n",
    "            info = col.split('_')\n",
    "            rect = info[2]\n",
    "            if rect == 'Rectangle':\n",
    "                continue\n",
    "            textNum = int(info[1].split()[0])-1\n",
    "            rectNum = int(rect.split()[1])-1\n",
    "            try:\n",
    "                coWord = lemTxt[textNum][rectNum]\n",
    "            except:\n",
    "#                 print(\"error\"+str(textNum))\n",
    "                continue\n",
    "            for key in seqDict.keys():\n",
    "                if col.startswith(key):\n",
    "                    colName = coWord+seqDict[key]\n",
    "                    df.iloc[textNum][colName] = eye.iloc[5,j]\n",
    "                    break\n",
    "        result.append(df)\n",
    "#         break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lemTxt = textProc()\n",
    "eyeMatched = matchEyeData(lemTxt,eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resource/eyeMatched.pkl', 'wb') as f:\n",
    "    pickle.dump(eyeMatched, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP2: Prepare eye-tracking data for ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resource/eyeMatched.pkl', 'rb') as f:\n",
    "    eyeMatched = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = pd.concat(eyeMatched)\n",
    "eye_label = pd.read_pickle('../resource/raw_data')['label'].to_numpy().astype('int').tolist()*len(eyeMatched)\n",
    "\n",
    "data = finalData.to_numpy()\n",
    "label = np.array(eye_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runIt(data,label,splits = 3, lowResource = False):\n",
    "    clfs = [LogisticRegression(), LinearSVC(),KNeighborsClassifier()]\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    X = data\n",
    "    y = label\n",
    "    for clf in clfs:\n",
    "        print(clf)\n",
    "        for  train_index,test_index in skf.split(data,label):\n",
    "            if lowResource:\n",
    "                tmp = test_index\n",
    "                test_index = train_index\n",
    "                train_index = tmp\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            clf.fit(X_train,y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print (accuracy_score(y_test,y_pred))\n",
    "            print (confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.5294117647058824\n",
      "[[2 7]\n",
      " [1 7]]\n",
      "0.7058823529411765\n",
      "[[4 4]\n",
      " [1 8]]\n",
      "0.6875\n",
      "[[3 5]\n",
      " [0 8]]\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "0.5882352941176471\n",
      "[[5 4]\n",
      " [3 5]]\n",
      "0.6470588235294118\n",
      "[[4 4]\n",
      " [2 7]]\n",
      "0.6875\n",
      "[[4 4]\n",
      " [1 7]]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "0.47058823529411764\n",
      "[[0 9]\n",
      " [0 8]]\n",
      "0.5294117647058824\n",
      "[[0 8]\n",
      " [0 9]]\n",
      "0.4375\n",
      "[[4 4]\n",
      " [5 3]]\n"
     ]
    }
   ],
   "source": [
    "# single person\n",
    "runIt(eyeMatched[0].to_numpy(),pd.read_pickle('../resource/raw_data')['label'].to_numpy().astype('int'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
